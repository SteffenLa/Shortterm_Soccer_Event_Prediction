{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T08:26:00.873053Z",
     "start_time": "2024-05-13T08:26:00.278806Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..//..')\n",
    "\n",
    "from models.linear import LogisticRegressionClassifier\n",
    "from joblib import load\n",
    "from utils.data import split_match_into_samples, data_generator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "def Save_to_csv (df, filename):\n",
    "    df.to_csv(filename, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c083d1cfb20ae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T08:26:10.491005Z",
     "start_time": "2024-05-13T08:26:10.454808Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_single_match(match_path, filename, window_length_lookback, window_length_outlook, hidden, PI_rank, pi_list_selected, scaler, clf): \n",
    "    \n",
    "    # Load the match data using the given data generator\n",
    "    match = next(iter(data_generator([match_path])))\n",
    "\n",
    "    # Split the match into time series samples for input (x), labels (y), and metadata (labels)\n",
    "    x, y, labels = split_match_into_samples(\n",
    "        match,\n",
    "        window_length_lookback=window_length_lookback,\n",
    "        window_length_outlook=window_length_outlook,\n",
    "        hidden=hidden,\n",
    "        pi_list=pi_list_selected,             # Select specific performance indicators\n",
    "        training_goal=\"isGoal\",               # Target label: whether a goal occurs\n",
    "        folding=['any_above', 0],             # Custom sample filtering logic\n",
    "        sample_rate=1                         # No downsampling\n",
    "    )\n",
    "\n",
    "    # Extend x with zeros for the full PI list (to ensure consistent dimensionality)\n",
    "    x_extended = np.zeros((x.shape[0], x.shape[1], len(pi_list)))\n",
    "    x_extended[:, :, indices] = x  # Insert selected PI values at their original indices\n",
    "\n",
    "    # Normalize the extended features using the fitted scaler\n",
    "    x = scaler.transform(x_extended.reshape(-1, x_extended.shape[-1])).reshape(x_extended.shape)[:, :, indices]\n",
    "\n",
    "    # Create a \"zero\" input sample (all features are zero, for baseline comparison)\n",
    "    zero_input = np.zeros_like(x_extended)\n",
    "    zero_input = scaler.transform(zero_input.reshape(-1, zero_input.shape[-1])).reshape(zero_input.shape)[0:1, :, indices]\n",
    "\n",
    "    # --- Create lookback windows for Home and Away teams ---\n",
    "\n",
    "    # Split the data into two halves (Home and Away perspective)\n",
    "    x1 = x[:(len(labels) // 2)]  # Home\n",
    "    y1 = y[:(len(labels) // 2)].astype(int)\n",
    "\n",
    "    x2 = x[(len(labels) // 2):]  # Away\n",
    "    y2 = y[(len(labels) // 2):].astype(int)\n",
    "\n",
    "    # Create synthetic starting sequences for the first prediction step\n",
    "    # Fill beginning of sequence with zero_input to mimic temporal context\n",
    "    x1_start = np.stack([\n",
    "        np.concatenate([zero_input[0, :-i], x1[0, :i]], axis=0)\n",
    "        for i in range(1, window_length_lookback + 1)\n",
    "    ], axis=0)\n",
    "\n",
    "    x2_start = np.stack([\n",
    "        np.concatenate([zero_input[0, :-i], x2[0, :i]], axis=0)\n",
    "        for i in range(1, window_length_lookback + 1)\n",
    "    ], axis=0)\n",
    "\n",
    "    # Flatten the input sequences for classifier input\n",
    "    x1 = np.reshape(x1, (len(x1), -1))\n",
    "    x1_start = np.reshape(x1_start, (len(x1_start), -1))\n",
    "\n",
    "    x2 = np.reshape(x2, (len(x2), -1))\n",
    "    x2_start = np.reshape(x2_start, (len(x2_start), -1))\n",
    "\n",
    "    # --- Run Predictions ---\n",
    "\n",
    "    # Predict probabilities for the actual input and synthetic starting states\n",
    "    pred1 = clf.predict_proba(x1)\n",
    "    pred2 = clf.predict_proba(x2)\n",
    "\n",
    "    pred1_start = clf.predict_proba(x1_start)\n",
    "    pred2_start = clf.predict_proba(x2_start)\n",
    "\n",
    "    pred_zero = clf.predict_proba(np.reshape(zero_input, (1, -1)))  # Optional: could be logged or used as baseline\n",
    "\n",
    "    # Prepend synthetic predictions to actual predictions\n",
    "    pred1 = np.concatenate([pred1_start, pred1], axis=0)\n",
    "    pred2 = np.concatenate([pred2_start, pred2], axis=0)\n",
    "\n",
    "    # --- Smooth predictions with averaging ---\n",
    "\n",
    "    # Apply moving average (with triangular padding) to smooth prediction curves\n",
    "    pred1_averaged = np.concatenate([\n",
    "        np.array([pred1[:i].mean() for i in range(1, window_length_outlook)]),\n",
    "        np.array([np.mean(pred1[i:i + window_length_outlook]) for i in range(len(pred1) - window_length_outlook + 1)]),\n",
    "        np.array([pred1[-i:].mean() for i in range(window_length_outlook - 1, 0, -1)])\n",
    "    ])\n",
    "\n",
    "    pred2_averaged = np.concatenate([\n",
    "        np.array([pred2[:i].mean() for i in range(1, window_length_outlook)]),\n",
    "        np.array([np.mean(pred2[i:i + window_length_outlook]) for i in range(len(pred2) - window_length_outlook + 1)]),\n",
    "        np.array([pred2[-i:].mean() for i in range(window_length_outlook - 1, 0, -1)])\n",
    "    ])\n",
    "\n",
    "    # Optionally compute standard deviation for uncertainty estimation\n",
    "    pred1_std = np.concatenate([\n",
    "        np.array([pred1[:i].std() for i in range(1, window_length_outlook)]),\n",
    "        np.array([np.std(pred1[i:i + window_length_outlook]) for i in range(len(pred1) - window_length_outlook + 1)]),\n",
    "        np.array([pred1[-i:].std() for i in range(window_length_outlook - 1, 0, -1)])\n",
    "    ])\n",
    "\n",
    "    pred2_std = np.concatenate([\n",
    "        np.array([pred2[:i].std() for i in range(1, window_length_outlook)]),\n",
    "        np.array([np.std(pred2[i:i + window_length_outlook]) for i in range(len(pred2) - window_length_outlook + 1)]),\n",
    "        np.array([pred2[-i:].std() for i in range(window_length_outlook - 1, 0, -1)])\n",
    "    ])\n",
    "\n",
    "    # Create a DataFrame to store predictions\n",
    "    predictions = pd.DataFrame()\n",
    "    predictions[\"Home\"] = pred1_averaged  # Averaged probabilities for Home team\n",
    "    predictions[\"Away\"] = pred2_averaged  # Averaged probabilities for Away team\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    Save_to_csv(predictions, filename + \"_predictions_\" + PI_rank + \".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the logistic regression model as trained models\n",
    "model_config = {\n",
    "    \"class_weight\": \"balanced\",     # Adjusts weights inversely proportional to class frequencies (for imbalanced datasets)\n",
    "    \"n_jobs\": -1,                   # Use all available CPU cores for parallel processing\n",
    "    \"max_iter\": 5000                # Maximum number of iterations for solver convergence\n",
    "}\n",
    "\n",
    "# List of performance indicators (PIs) used in the study\n",
    "pi_list = ['Shot', 'BP', 'BP3rd', 'BPBox', 'Goal', 'Cross','PassBox', 'Pass3rd', 'Corner', 'TackWon', 'OutpOpp', 'EntrBox', 'Entr3rd', 'Danger',\n",
    "           'Shot_diff', 'BP_diff', 'BP3rd_diff', 'BPBox_diff', 'Goal_diff', 'Cross_diff','PassBox_diff', 'Pass3rd_diff', 'Corner_diff', 'TackWon_diff', 'OutpOpp_diff', 'EntrBox_diff', 'Entr3rd_diff', 'Danger_diff']\n",
    "\n",
    "PI_rank = \"rank1\" ## Select the PI ranking level to apply; options: 'rank1', 'rank2', or 'rank3'\n",
    "\n",
    "# Load the appropriate pre-trained model and PI subset based on selected PI ranking\n",
    "if PI_rank == \"rank3\":\n",
    "    clf = LogisticRegressionClassifier.load_from_path(\"../models/ApplicationScenario_rank3_LR-Danger-Entr3rd_diff\")     # Load rank 3 logistic regression model\n",
    "    indices = [pi_list.index(\"Entr3rd_diff\"), pi_list.index(\"Danger\")]      # Select relevant PI indices and names\n",
    "    pi_list_selected = [\"Entr3rd_diff\", \"Danger\"]\n",
    "    window_length_lookback = 180                                            # Number of input window intervalls\n",
    "elif PI_rank == \"rank2\":\n",
    "    clf = LogisticRegressionClassifier.load_from_path(\"../models/ApplicationScenario_rank2_LR-Danger_diff-TackWon\")    # Load rank 2 logistic regression model\n",
    "    indices = [pi_list.index(\"TackWon\"), pi_list.index(\"Danger_diff\")]    \n",
    "    pi_list_selected = [\"TackWon\", \"Danger_diff\"]\n",
    "    window_length_lookback = 60\n",
    "elif PI_rank == \"rank1\":\n",
    "    clf = LogisticRegressionClassifier.load_from_path(f\"../models/ApplicationScenario_rank1_LR-OutpOpp_diff-TackWon\")     # Load rank 1 logistic regression model\n",
    "    indices = [pi_list.index(\"OutpOpp_diff\"), pi_list.index(\"TacklingWon_Event\")]    \n",
    "    pi_list_selected = [\"OutpOpp_diff\", \"TackWon\"]\n",
    "    window_length_lookback = 60\n",
    "\n",
    "window_length_outlook = 36  # Number of prediction window intervalls\n",
    "hidden = 12                 # Number of hidden window intervalls\n",
    "\n",
    "#Predict event for an unseen match\n",
    "scaler = load(\"MinMaxScaler.pkl\")   # Load feature scaling object\n",
    "filename = \"unseen_match\"           # Define input match file name\n",
    "match_path = \"../data/\"+filename    # Build full path to the match file\n",
    "\n",
    "# Process the match with the selected model and parameters\n",
    "process_single_match(\n",
    "    match_path,                 # Path to the match data\n",
    "    filename,                   # Match identifier\n",
    "    window_length_lookback, \n",
    "    window_length_outlook, \n",
    "    hidden, \n",
    "    PI_rank, \n",
    "    pi_list_selected, \n",
    "    scaler,                     # Feature scaler for input normalization\n",
    "    clf)                        # Trained classifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
